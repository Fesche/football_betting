{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "#from keras.models import load_model\n",
    "import urllib.request\n",
    "from urllib3 import PoolManager\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gjenstår: Hent odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find odds for 7 days at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source 1: soccerbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import urllib.request\n",
    "games = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# url_string2 = None\n",
    "# with urllib.request.urlopen('http://www.soccerbase.com/matches/home.sd?type=2') as response:\n",
    "#     gzipFile = gzip.GzipFile(fileobj=response)\n",
    "#     url_string2 = gzipFile.read().decode(\"UTF-8\")\n",
    "#     url_string2 = re.search('(?<=soccer.gamelist.Timekeeper.addGames\\({).*?(?=soccer.gamelist)', url_string2)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches = re.finditer('(?<=\\=)(.*?)\\_V\\_(.*?)\\=(.*?)\\\"', url_string2)\n",
    "# for match in matches:\n",
    "#     games.append([match[3],re.sub(\"_\", \" \", match[1]).lower(),re.sub(\"_\", \" \", match[2]).lower()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source 2: supersport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = urllib.request.urlopen('https://www.supersport.com/football/fixtures')\n",
    "# url_string = response.read()\n",
    "# url_string = url_string.decode(\"UTF-8\")\n",
    "# url_string = re.search('(?<=FIXTURES)(.|\\s)*', url_string)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates = re.finditer(\"(?<=Header\\\">)(.*?)(?=class=\\\"table)\", url_string)\n",
    "\n",
    "# for day in dates:\n",
    "    \n",
    "#     date = re.search('.*?(?=</td>)',day[0])[0]\n",
    "#     matches = re.finditer(\"(?<=>)(..:..)(.*?)(?=</td><td class)\",day[0])\n",
    "    \n",
    "#     for match in matches:\n",
    "#         time_of_match = match[0][:5]\n",
    "#         teams_re = re.finditer(\"(?<=st\\'>)(.*?)(?=</td>)\", match[0])\n",
    "#         game = [date]\n",
    "#         for team in teams_re:\n",
    "            \n",
    "#             game.append(team[0].lower())\n",
    "#         games.append(game)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source 3: thefishy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_string3 = None\n",
    "with urllib.request.urlopen('https://thefishy.co.uk/nextweeksfixtures.php') as response:\n",
    "    url_string3 = response.read().decode(\"UTF-8\") + \" 12/12</th>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = re.finditer(\"(\\ ../..<(.|\\s)*?)(?=\\ \\w\\w/\\w\\w</th>)\", url_string3)\n",
    "\n",
    "for date in dates:\n",
    "    day = date[0][1:6] + \"/18\"\n",
    "    matches = re.finditer(\"(?<=\\'>)(.*?)\\ v\\ (.*?)(?=<)\", date[0])\n",
    "    for match in matches:\n",
    "        away_team = match[2]\n",
    "        home_team = re.search('(?<=team2)(.*?>)(.*?)(?=$)',match[1])[2]\n",
    "        \n",
    "#         print(home_team, away_team)\n",
    "        \n",
    "        games.append([day, home_team.lower(), away_team.lower()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading  http://www.football-data.co.uk/mmz4281/2021/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/1920/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/1819/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/1718/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/1617/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/1516/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/1415/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/1314/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/1213/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/1112/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/1011/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/0910/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/0809/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/0708/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/0607/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/0506/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/0405/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/0304/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/0203/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/0102/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/0001/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/9900/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/9899/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/9798/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/9697/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/9596/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/9495/data.zip\n",
      "Downloading  http://www.football-data.co.uk/mmz4281/9394/data.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_0.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_1.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_10.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_11.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_12.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_13.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_14.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_15.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_16.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_17.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_18.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_19.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_2.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_20.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_21.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_22.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_23.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_24.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_25.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_26.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_27.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_3.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_4.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_5.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_6.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_7.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_8.zip\n",
      "unzipping  ../../Football_Data/Zipstash\\data_9.zip\n"
     ]
    }
   ],
   "source": [
    "%run update_stash.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seasons = []\n",
    "for filename in os.listdir('C:/Users/bfesc/Documents/Football_Data/Stash/'):\n",
    "    #if filename[0] == 'B':\n",
    "    with open(\"C:/Users/bfesc/Documents/Football_Data/Stash/\" + filename) as file:\n",
    "        season = file.read().rstrip().split('\\n')\n",
    "        for i in range(len(season)):\n",
    "            season[i] = season[i].rstrip(',').split(',')\n",
    "            for j in range(len(season[i])):\n",
    "                season[i][j] = season[i][j].lower()\n",
    "        all_seasons.append(season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Div', 'Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'WHH', 'WHD', 'WHA']\n",
    "columns = [col.lower() for col in columns]\n",
    "all_data = pd.DataFrame(columns=columns)\n",
    "for season in all_seasons:\n",
    "    if not np.in1d(columns, season[0]).all():\n",
    "        continue\n",
    "    if len(season[0]) != max([len(s) for s in season]):\n",
    "        for i in range(len(season)):\n",
    "            season[i] = season[i][:len(season[0])]\n",
    "    df = pd.DataFrame(season[1:])\n",
    "    df.columns = season[0]\n",
    "    all_data = all_data.append(df[columns])\n",
    "    \n",
    "all_data['date'] = pd.to_datetime(all_data['date'], dayfirst=True)\n",
    "all_data.index = all_data['date']\n",
    "all_data = all_data.drop(columns=['date','div'])\n",
    "for column in all_data.columns:\n",
    "    all_data = all_data[pd.notnull(all_data[column])]\n",
    "all_data = all_data[pd.notnull(all_data.index)]\n",
    "all_data = all_data.iloc[np.where(all_data['whh'] != \"\")]\n",
    "all_data = all_data.iloc[np.where(all_data['whd'] != \"\")]\n",
    "all_data = all_data.iloc[np.where(all_data['wha'] != \"\")]\n",
    "all_data = all_data.iloc[np.where(all_data['fthg'] != \"\")]\n",
    "all_data = all_data.sort_index(ascending=False)\n",
    "all_data['ftr'].iloc[np.where(all_data['ftr'] == 'a')] = 0\n",
    "all_data['ftr'].iloc[np.where(all_data['ftr'] == 'd')] = 1\n",
    "all_data['ftr'].iloc[np.where(all_data['ftr'] == 'h')] = 2\n",
    "all_data['fthg'] = all_data['fthg'].astype(int)\n",
    "all_data['ftag'] = all_data['ftag'].astype(int)\n",
    "all_data['whh'] = all_data['whh'].astype(np.float32)\n",
    "all_data['whd'] = all_data['whd'].astype(np.float32)\n",
    "all_data['wha'] = all_data['wha'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from difflib import SequenceMatcher\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def unknown_team(home_team, away_team, team_dict, unknown = \"away\"):\n",
    "\n",
    "    if unknown == \"away\":\n",
    "        team_scores = []\n",
    "        teams = team_dict[home_team]['awayteam'].unique() #Away or HomeTeam doesnt really matter \n",
    "        \n",
    "        team_scores = process.extract(away_team,teams)\n",
    "        #for team in teams:\n",
    "        #    team_scores.append(SequenceMatcher(None,team,away_team).ratio())\n",
    "        \n",
    "        if team_scores[0][1] < 80:\n",
    "            return None\n",
    "        \n",
    "        #team_scores = np.argsort(team_scores)\n",
    "        \n",
    "        away_team = team_scores[0][0]\n",
    "    else:\n",
    "        teams = team_dict[away_team]['hometeam']\n",
    "        team_scores = []\n",
    "            \n",
    "        team_scores = process.extract(home_team,teams)\n",
    "        \n",
    "        if team_scores[0][1] < 80:\n",
    "            return None\n",
    "        \n",
    "        #team_scores = np.argsort(team_scores)\n",
    "        \n",
    "        home_team = team_scores[0][0]\n",
    "        \n",
    "    return home_team, away_team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_team_dicts(data):\n",
    "    \n",
    "    ht = data[\"hometeam\"].str.lower()\n",
    "    at = data[\"awayteam\"].str.lower()\n",
    "    \n",
    "    all_teams = np.unique(np.append(ht, at))\n",
    "    team_dict = {}\n",
    "    \n",
    "    for team in all_teams:\n",
    "        team_dict[team] = data.iloc[np.where(np.logical_or(ht == team, \n",
    "                                                      at == team))].sort_index(ascending=False)\n",
    "        \n",
    "    return team_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_dict = make_team_dicts(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13333333333333333"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SequenceMatcher(None,\"dortmund\",\"bayerrr\").ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dortmund', 'bayern munich')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "unknown_team(\"dortmund\", \"bayern\", team_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_live_data(live_data, team_dict):\n",
    "\n",
    "\n",
    "    training_data = pd.DataFrame(columns=['Date','HomeTeam', 'AwayTeam', 'DaysSinceLastHTMatch', 'DaysSinceLastATMatch', 'HomeTeamForm', 'AwayTeamForm',\n",
    "                                          'HomeTeamHomeForm','AwayTeamAwayForm', 'HomeTeamOffense', 'HomeTeamDefense',\n",
    "                                          'AwayTeamOffense', 'AwayTeamDefense', 'LastInterTeamGame', \n",
    "                                           'Result'])\n",
    "\n",
    "\n",
    "    history = pd.Timedelta('90d')\n",
    "    year = pd.Timedelta('365d')\n",
    "    for i in tqdm(range(len(live_data))):#\n",
    "        game = live_data[i]\n",
    "        home_team = game[1]\n",
    "        away_team = game[2]\n",
    "        game_date = pd.to_datetime(game[0]) \n",
    "\n",
    "        if home_team not in team_dict.keys() and away_team not in team_dict.keys():\n",
    "            continue\n",
    "        elif home_team not in team_dict.keys():\n",
    "            try:\n",
    "                home_team, away_team = unknown_team(home_team, away_team, team_dict, unknown=\"home\")\n",
    "            except:\n",
    "                print(f\"fant ikke {home_team}\")\n",
    "                continue\n",
    "        elif away_team not in team_dict.keys():\n",
    "            try:\n",
    "                home_team, away_team = unknown_team(home_team, away_team, team_dict, unknown=\"away\")\n",
    "            except:\n",
    "                print(f\"fant ikke {away_team}\")\n",
    "                continue\n",
    "        ht_games = team_dict[home_team].loc[game_date - pd.Timedelta('1h'):game_date - year]\n",
    "        at_games = team_dict[away_team].loc[game_date - pd.Timedelta('1h'):game_date - year]\n",
    "\n",
    "        #result = game['FTR']\n",
    "        result = 0\n",
    "\n",
    "        ht_hgames = ht_games.iloc[np.where(ht_games['hometeam'] == home_team)]\n",
    "        ht_agames = ht_games.iloc[np.where(ht_games['awayteam'] == home_team)]\n",
    "\n",
    "        at_hgames = at_games.iloc[np.where(at_games['hometeam'] == away_team)]\n",
    "        at_agames = at_games.iloc[np.where(at_games['awayteam'] == away_team)]\n",
    "\n",
    "\n",
    "        if len(ht_hgames) > 1 and len(at_agames) > 1:\n",
    "\n",
    "            ht_time_diff = np.log((game_date - ht_games.index).days.values + 1)\n",
    "            at_time_diff = np.log((game_date - at_games.index).days.values + 1)\n",
    "\n",
    "            ht_h_td = ht_time_diff[np.where(ht_games['hometeam'] == home_team)]\n",
    "            ht_a_td = ht_time_diff[np.where(ht_games['awayteam'] == home_team)]\n",
    "            at_h_td = at_time_diff[np.where(at_games['hometeam'] == away_team)]\n",
    "            at_a_td = at_time_diff[np.where(at_games['awayteam'] == away_team)]\n",
    "\n",
    "\n",
    "            it_games = np.append(np.where(ht_hgames['awayteam'] == away_team)[0],\n",
    "                                 np.where(ht_agames['hometeam'] == away_team)[0])\n",
    "\n",
    "            litgr = 0\n",
    "            if len(it_games) > 0:\n",
    "                litgr += np.mean((ht_games['fthg'].iloc[it_games].values - ht_games['ftag'].iloc[it_games].values) / ht_time_diff[it_games])\n",
    "\n",
    "            dslhtm = ht_time_diff[0]\n",
    "            dslatm = at_time_diff[0]\n",
    "\n",
    "            ht_form = np.mean(np.append(((ht_hgames['fthg'].values - ht_hgames['ftag'].values) / ht_h_td),\n",
    "                              (ht_agames['ftag'].values - ht_agames['fthg'].values) / ht_a_td))\n",
    "            at_form = np.mean(np.append((at_hgames['fthg'].values - at_hgames['ftag'].values) / at_h_td,\n",
    "                              (at_agames['ftag'].values - at_agames['fthg'].values) / at_a_td))\n",
    "\n",
    "            ht_hform = np.mean((ht_hgames['fthg'].values - ht_hgames['ftag'].values) / ht_h_td)\n",
    "            at_aform = np.mean((at_agames['ftag'].values - at_agames['fthg'].values) / at_a_td)\n",
    "\n",
    "            hto = np.mean(np.append(ht_hgames['fthg'].values / ht_h_td, ht_agames['ftag'].values / ht_a_td))\n",
    "            htd = -np.mean(np.append(ht_hgames['ftag'].values / ht_h_td, ht_agames['fthg'].values /ht_a_td))\n",
    "\n",
    "            ato = np.mean(np.append(at_hgames['fthg'] / at_h_td, at_agames['ftag'].values / at_a_td))\n",
    "            atd = -np.mean(np.append(at_hgames['ftag'].values / at_h_td, at_agames['fthg'].values / at_a_td))\n",
    "\n",
    "            \n",
    "            training_data = training_data.append(pd.DataFrame([[game_date,home_team, away_team, dslhtm, dslatm, ht_form, at_form, ht_hform, at_aform,\n",
    "                                                                hto, htd, ato, atd, litgr, result]], columns=training_data.columns))\n",
    "\n",
    "    return training_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                               | 18/844 [00:02<02:57,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke celta vigo b\n",
      "fant ikke zamora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███                                                                              | 32/844 [00:03<01:48,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke cd ebro\n",
      "fant ikke ud ibiza-eivissa\n",
      "fant ikke fc andorra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▍                                                                             | 36/844 [00:03<01:22,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke cornella\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▉                                                                            | 51/844 [00:04<00:52, 15.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke linense\n",
      "fant ikke ss reyes\n",
      "fant ikke internacional de madrid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▎                                                                           | 56/844 [00:05<01:15, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke wehen wiesbaden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▏                                                                         | 75/844 [00:05<00:44, 17.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke legnago salus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████                                                                         | 84/844 [00:06<00:36, 20.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke imolese calcio\n",
      "fant ikke casertana\n",
      "fant ikke paganese\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▎                                                                    | 120/844 [00:08<01:01, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke casa pia\n",
      "fant ikke cova da piedade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████                                                              | 191/844 [00:10<00:38, 17.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke istanbul basaksehir\n",
      "fant ikke sudtirol\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████                                                             | 201/844 [00:10<00:29, 21.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke deinze\n",
      "fant ikke covilha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████████████▉                                                            | 210/844 [00:10<00:24, 26.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke sheff wed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████▋                                                          | 229/844 [00:11<00:39, 15.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke harrogate town\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▋                                                       | 261/844 [00:14<00:49, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke sv darmstadt 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████████████████▉                                                      | 274/844 [00:16<00:58,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke chambly thelle\n",
      "fant ikke pau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▎                                                     | 277/844 [00:17<01:41,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke rumilly vallières\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████▋                                                     | 281/844 [00:18<01:25,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke canet roussillon\n",
      "fant ikke kings lynn town\n",
      "fant ikke dover\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████                                                     | 285/844 [00:18<01:04,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke maidenhead utd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████▉                                             | 368/844 [00:19<00:29, 16.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke borussia monchengladbach\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████████████████████                                            | 381/844 [00:20<00:23, 19.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke sv tuerkguecue ataspor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████▋                                           | 387/844 [00:20<00:18, 24.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke lecco\n",
      "fant ikke monopoli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▌                                          | 396/844 [00:21<00:32, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke villefranche\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████▊                                | 504/844 [00:23<00:05, 59.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke istanbul basaksehir\n",
      "fant ikke monterrey\n",
      "fant ikke avranches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▋                             | 535/844 [00:23<00:03, 79.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke cholet\n",
      "fant ikke mvv maastricht\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████▉                           | 559/844 [00:24<00:04, 68.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke sheff wed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████▌                        | 586/844 [00:25<00:06, 38.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke harrogate town\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████████▋                      | 608/844 [00:25<00:06, 36.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke ue llagostera\n",
      "fant ikke la nucia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████████████▋                    | 630/844 [00:26<00:04, 48.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke meppen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████                   | 644/844 [00:27<00:06, 29.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke pau\n",
      "fant ikke villefranche\n",
      "fant ikke concarneau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 844/844 [00:28<00:00, 30.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fant ikke vizela\n",
      "fant ikke fatih karagumruk\n",
      "fant ikke club atlas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = make_live_data(games,team_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237, 15)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_playing = np.unique(np.array(games)[:,1].tolist() + np.array(games)[:,2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_odds_betfair():\n",
    "    html = PoolManager()\n",
    "    webpage = html.request(\"GET\",\"https://www.betfair.com/sport/football\")\n",
    "\n",
    "    webpage_l = webpage.data.decode(\"UTF-8\").lower()\n",
    "\n",
    "    end_cue = \"</span>\\n</div>\\n</a>\\n</div>\\n</div>\\n</div>\\n</li>\"\n",
    "    start_cue = '<div class=\"avb-col avb-col-markets\">'\n",
    "\n",
    "    wp_all_games = re.findall(f\"{start_cue}.*?{end_cue}\",webpage_l,flags=re.DOTALL)\n",
    "\n",
    "    game_odds = []\n",
    "\n",
    "    for wp in wp_all_games:\n",
    "        try:\n",
    "            odds = [float(o) for o in re.findall(\"(?<=\\n)\\d{1,2}\\.\\d{1,2}(?=\\n)\",wp)[2:]]\n",
    "            hometeam, awayteam = re.findall('<span class=\"team-name\" title=\"(.*?)\">',wp)\n",
    "\n",
    "            game_odds.append({\"hometeam\" : hometeam,\n",
    "                                \"awayteam\" : awayteam,\n",
    "                                \"homeodds\" : odds[0],\n",
    "                                \"awayodds\" : odds[-1]})\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    return game_odds\n",
    "\n",
    "def kelly_criterion(prob_win, net_fractional_odds):\n",
    "    prob_loss = 1 - prob_win\n",
    "    \n",
    "    return (((net_fractional_odds*prob_win) - prob_loss) / prob_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n"
     ]
    }
   ],
   "source": [
    "odds = pd.DataFrame(get_odds_betfair())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds = odds.loc[~((odds.homeodds > 3) & (odds.awayodds > 3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inntil videre så settes treff på minst ett lag som krav.\n",
    "print(odds.loc[odds.hometeam.isin(teams_playing) | odds.awayteam.isin(teams_playing)].shape)\n",
    "data_with_odds = training_data.merge(odds,left_on=\"HomeTeam\",right_on=\"hometeam\",how=\"inner\")\n",
    "data_with_odds = data_with_odds.append(training_data.merge(odds,left_on=\"AwayTeam\",right_on=\"awayteam\",how=\"inner\"))\n",
    "data_with_odds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "gb = XGBClassifier()\n",
    "gb.load_model(\"model_2021.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'HomeTeam', 'AwayTeam', 'DaysSinceLastHTMatch',\n",
       "       'DaysSinceLastATMatch', 'HomeTeamForm', 'AwayTeamForm',\n",
       "       'HomeTeamHomeForm', 'AwayTeamAwayForm', 'HomeTeamOffense',\n",
       "       'HomeTeamDefense', 'AwayTeamOffense', 'AwayTeamDefense',\n",
       "       'LastInterTeamGame', 'Result', 'hometeam', 'awayteam', 'homeodds',\n",
       "       'awayodds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_odds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_odds = data_with_odds.rename(columns={\"homeodds\":\"HomeTeamOdds\",\"awayodds\":\"AwayTeamOdds\"}).drop_duplicates(subset=[\"HomeTeam\",\"AwayTeam\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 19)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_odds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>DaysSinceLastHTMatch</th>\n",
       "      <th>DaysSinceLastATMatch</th>\n",
       "      <th>HomeTeamForm</th>\n",
       "      <th>AwayTeamForm</th>\n",
       "      <th>HomeTeamHomeForm</th>\n",
       "      <th>AwayTeamAwayForm</th>\n",
       "      <th>HomeTeamOffense</th>\n",
       "      <th>HomeTeamDefense</th>\n",
       "      <th>AwayTeamOffense</th>\n",
       "      <th>AwayTeamDefense</th>\n",
       "      <th>LastInterTeamGame</th>\n",
       "      <th>Result</th>\n",
       "      <th>hometeam</th>\n",
       "      <th>awayteam</th>\n",
       "      <th>HomeTeamOdds</th>\n",
       "      <th>AwayTeamOdds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>rotherham</td>\n",
       "      <td>birmingham</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.110711</td>\n",
       "      <td>-0.157403</td>\n",
       "      <td>0.181479</td>\n",
       "      <td>-0.274192</td>\n",
       "      <td>0.371245</td>\n",
       "      <td>-0.260534</td>\n",
       "      <td>0.179934</td>\n",
       "      <td>-0.337336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rotherham</td>\n",
       "      <td>birmingham</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   HomeTeam    AwayTeam  DaysSinceLastHTMatch  \\\n",
       "0 2018-04-18  rotherham  birmingham              0.693147   \n",
       "\n",
       "   DaysSinceLastATMatch  HomeTeamForm  AwayTeamForm  HomeTeamHomeForm  \\\n",
       "0              1.386294      0.110711     -0.157403          0.181479   \n",
       "\n",
       "   AwayTeamAwayForm  HomeTeamOffense  HomeTeamDefense  AwayTeamOffense  \\\n",
       "0         -0.274192         0.371245        -0.260534         0.179934   \n",
       "\n",
       "   AwayTeamDefense LastInterTeamGame Result   hometeam    awayteam  \\\n",
       "0        -0.337336                 0      0  rotherham  birmingham   \n",
       "\n",
       "   HomeTeamOdds  AwayTeamOdds  \n",
       "0           2.7           2.5  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_odds.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_with_odds = data_with_odds.assign(LastInterTeamGame=lambda df: df.LastInterTeamGame.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_cols = ['DaysSinceLastHTMatch', 'DaysSinceLastATMatch', 'HomeTeamForm', 'AwayTeamForm',\n",
    "      'HomeTeamHomeForm','AwayTeamAwayForm', 'HomeTeamOffense', 'HomeTeamDefense',\n",
    "      'AwayTeamOffense', 'AwayTeamDefense', 'LastInterTeamGame', \n",
    "      'HomeTeamOdds', 'AwayTeamOdds']\n",
    "\n",
    "livepreds = gb.predict(data_with_odds[pred_cols])\n",
    "probs = gb.predict_proba(data_with_odds[pred_cols])#[range(len(livepreds)),livepreds.tolist()]\n",
    "odds = data_with_odds[[\"AwayTeamOdds\",\"Result\",\"HomeTeamOdds\"]].values[range(len(livepreds)),livepreds.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bet_size = -14.851893508062444\n",
      "2018-04-18 00:00:00: rotherham - birmingham \n",
      "Away\n",
      "\n",
      "bet_size = -13.459549270035192\n",
      "2018-04-18 00:00:00: rotherham - middlesbrough \n",
      "Away\n",
      "\n",
      "bet_size = -14.851893508062444\n",
      "2018-04-18 00:00:00: derby - birmingham \n",
      "Away\n",
      "\n",
      "bet_size = -31.203108501030602\n",
      "2018-04-18 00:00:00: cadiz - cordoba \n",
      "Away\n",
      "\n",
      "bet_size = -33.21925261758334\n",
      "2018-04-18 00:00:00: milan - genoa \n",
      "Home\n",
      "\n",
      "bet_size = -19.56980053386873\n",
      "2018-04-18 00:00:00: paris sg - st etienne \n",
      "Home\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BALANCE=933\n",
    "\n",
    "def bet_size(cash, n_bets, win_probs, odds):\n",
    "    return (cash*kelly_criterion(win_probs,odds-1)) / n_bets\n",
    "\n",
    "\n",
    "for i in range(len(livepreds)):\n",
    "    print(f\"bet_size = {bet_size(BALANCE,len(livepreds),probs[i],odds[i])}\")\n",
    "    print(f\"{data_with_odds.iloc[i].Date}: {data_with_odds.iloc[i].HomeTeam} - {data_with_odds.iloc[i].AwayTeam} \")\n",
    "    print([\"Away\",\"Draw\",\"Home\"][livepreds[i]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Det som må gjøres:\n",
    "#1) Hent uavgjort-data\n",
    "#2) Sjekk kelly-score for odds/probs for hver av utfallene\n",
    "#3) Hvis ett eller flere av utfallene har positiv kelly-score, anbefal det største!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37616694, 0.3002782 , 0.32355487],\n",
       "       [0.3784814 , 0.2988397 , 0.3226789 ],\n",
       "       [0.37616694, 0.3002782 , 0.32355487],\n",
       "       [0.42085052, 0.31897032, 0.2601792 ],\n",
       "       [0.11306633, 0.22409625, 0.66283745],\n",
       "       [0.0827442 , 0.13266684, 0.784589  ]], dtype=float32)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelly home score : -0.19\n",
      "Kelly away score : -0.10\n",
      "\n",
      "Kelly home score : -0.19\n",
      "Kelly away score : -0.09\n",
      "\n",
      "Kelly home score : -0.19\n",
      "Kelly away score : -0.10\n",
      "\n",
      "Kelly home score : -0.12\n",
      "Kelly away score : -0.20\n",
      "\n",
      "Kelly home score : -0.21\n",
      "Kelly away score : -0.24\n",
      "\n",
      "Kelly home score : -0.13\n",
      "Kelly away score : -0.19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_odds = data_with_odds[[\"HomeTeamOdds\",\"AwayTeamOdds\"]].values\n",
    "for i in range(len(livepreds)):\n",
    "    print(\"Kelly home score : {:.2f}\".format(kelly_criterion(probs[i,-1],all_odds[i,0]-1)))\n",
    "    print(\"Kelly away score : {:.2f}\".format(kelly_criterion(probs[i,0],all_odds[i,1]-1)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.784589, 1.24, -0.12585080729176032)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[i], odds[i], kelly_criterion(probs[i],odds[i]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03937087973442492"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kelly_criterion(np.mean(probs),np.mean(odds)-1)\n",
    "\n",
    "#bet_size(BALANCE,len(livepreds),probs,odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "966"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "161*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everton - tottenham \n",
    "blackburn - derby \n",
    "reading - cardiff \n",
    "crawley town - cheltenham \n",
    "st mirren - inverness c \n",
    "motherwell - morton \n",
    "girona - zaragoza \n",
    "leipzig - hoffenheim \n",
    "spal - ascoli \n",
    "lille - montpellier \n",
    "boavista - pacos ferreira \n",
    "antalyaspor - rizespor \n",
    "forfar - clyde \n",
    "preston - derby \n",
    "brentford - cardiff \n",
    "peterboro - northampton \n",
    "stevenage - cheltenham \n",
    "darmstadt - greuther furth \n",
    "bourg peronnas - orleans \n",
    "roda - nac breda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46973372, 0.269813  , 0.26045328], dtype=float32)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livepreds[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
